\chapter{CONCLUSION AND FUTURE WORKS}
\label{chap:concl}

\section{Summary}
In the  thesis discussed the foreground detection algorithm (Section \ref{sec:bst}) for identifying the active region segments in the frame. Four different algorithms, namely frame differencing, moving average filtering, eigen background subtraction and mixture of gaussian based detection, are described and their performances at different background conditions are studied. Eigen based background subtraction is proved to be robust on most of the dynamic scene conditions. Since it was observed that in most of the background situation a simple FD yielded results comparable to that of ES and due to its swiftness FD was prefered. Later reviewed variety of saliency algorithms (Section \ref{sec:sal}), viz. hierarchical color based, context aware, spectral distribution based and region contrast, computed its efficiency on some standard dataset. Among the proposed methods, region based color and texture contrast technique by combining contrast and distribution cues into a computational superpixel based framework rendered a high quality saliency maps

\par Following which we fused the variation measure from background subtraction and saliency map measure, obtained a visual attentaion score that determine the probability of an event occuring at given pixel in the frame. Temporal smoothening (Section \ref{sec:ts}) over the visual attention score helped obtain clearer boundaries distinguishing source of the event. It also smoothens the mask obtained over the video segment. Also a novel approach for tracking (Section \ref{sec:track}) was propososed to generate bounding box from the smoothned mask on every frame, this further boosts resistance to sudden variation.

\par After obtaining bounding box, the inborn convolutional neural network (Section \ref{sec:cnn}) was provided these bounding box for the event classification and it was observed that video segment localized on the probable event region yielded a better model accuracy compared to the complete video segment. The performance of some processed features rather than a comman raw color pixels to CNN was studied, but figured out the raw color features outperformed for the given dataset then the processed features. Also from the experiments it was evident  that a hierarchical manner of classifying events using multiple classifier outperform the classification using the single big classifier also enabling to train models concurently and rapidly.

\section{Criticism}
\begin{itemize}
	\item{Focused only spatial localization and failed to consider the temporal localization which is very important in any real time video. With the temporal localization the process of smoothening could have been eliminated}
	\item{Instead of Event tracking by feature matching on every frame, a combination of our approach and standard tracking algorithm (like KLT algorithm) can be tried. Once the tracking window is obtained we could use KLT algorithm to track it and regulate it by our approach for obtaining the mask, it handles entry and exit of objects.}
	\item{Rather than color and texture based saliency, optical flow based saliency alone might have worked for obtaining the confined mask as event regions are based on the flow of indvidual pixels.}
\end{itemize}

\section{Future Work}
Would like to revisit the indigenous convolutional neural network, to incorporate hierarchical learning. Where we train the first layer of CNN  and determine the classes that are quite similar based on CNN feature clustering. In subsequent layers we train the CNN to be able to discriminate the classes which were considered similar in previous layer. This might help raise the performance of the classification on a large dataset as task is being delegated to multiple simple classifiers.
\par Also want to explore ways for associating the objects and events that are present in the given video segment and build a knowledge base by annotating them in the video. It helps for more sophisticated video content retrieval allowing to step to the queried region within a video.