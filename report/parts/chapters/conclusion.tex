\chapter{CONCLUSION AND FUTURE WORKS}
\label{chap:concl}

\section{Summary}
A novel framework for event recognition has been proposed, which has four main building blocks : background subtraction, saliency, temporal smoothening and recognition using 3D convolutional neural network.  In background subtraction (Section \ref{sec:bst}), four different algorithms, namely frame differencing, moving average filtering, eigen background subtraction and mixture of Gaussian based detection, are described and their performances at different background conditions are being studied.  Among all eigen based background subtraction is shown to be robust on most of the dynamic scene conditions, but because of its slowness framed differencing was preferred.  In saliency (Section \ref{sec:sal}), hierarchical color based, context aware, spectral distribution based and region contrast were studied and it was evident that region color (texture) contrast approach had rendered a high quality saliency maps.

\par Temporal smoothening enables to focus the visual attention score (the probability of an event occurring at given pixel) across frames that are obtained by fusing the variation measure of background subtraction and saliency map measure.  It helped to obtain a clear boundaries distinguishing source of the event.  Spatio temporal volume (STV) is generated from the smoothened mask by a unique approach of tracking which further boosts resistance to sudden variation.

\par The indigenous convolutional neural network (CNN) was used for event classification of video segment from the  obtained STV.  It was observed that these localized video segment (most probable event region) yielded a better model accuracy compared to the complete video segment.  It is also evident from the experiments revealed that raw color features as input to CNN-3D outperformed the processed features for the studied dataset.  A hierarchical manner of classifying events was analysed as it enables to train models concurrently and rapidly.  A deep examination disclose its excellence over a single large classifier.

\par This framework enlighten a new approach for solving problems in different applications like surveillance, automated annotation, etc.

\section{Criticism}
\begin{itemize}
	\item{Focused only on spatial localization and failed to consider the temporal localization which is very important in any real time video.  With the temporal localization the process of smoothening could have been eliminated.}
	\item{Instead of event tracking by feature matching on every frame, a combination of current approach and standard tracking algorithm like Kanade–Lucas–Tomasi feature tracker (KLT) can be tried.  Once a tracking window is obtained, the KLT algorithm can be use to track it and current approach can regulate entry and exit of objects.}
	\item{Along with color and texture based saliency, optical flow based saliency might have helped to obtain the confined mask corresponding to an event.}
\end{itemize}

\section{Future Work}
It would be worthwhile to revisit the indigenous convolutional neural network (CNN), to incorporate hierarchical learning.  In this approach, the first layer of CNN will be trained and then classes that are quite similar will be clustered based on CNN bottleneck features.  Subsequent layers will be trained in a way to discriminate the classes which were considered similar in the previous layer.  This will help to improve the performance of the classification on a large dataset, as the task is being delegated efficiently to multiple simple classifiers.
\par The other application that can be targetted is video annotation that aims at associating the objects and events that are present in the given video segment to build a knowledge base by annotating them in the video.  It helps sophisticated video content retrieval by allowing to step to the queried region within a video.