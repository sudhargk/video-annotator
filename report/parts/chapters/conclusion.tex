\chapter{CONCLUSION AND FUTURE WORKS}
\label{chap:concl}

\section{Summary}
A novel framework for event recognition has been proposed, which has four main building blocks : background subtraction, saliency, temporal smoothening and recognition using 3D convolutional neural network. In background subtraction (Section \ref{sec:bst}) , four different algorithms, namely frame differencing, moving average filtering, eigen background subtraction and mixture of Gaussian based detection, are described and their performances at different background conditions are being studied.  Among all eigen based background subtraction is shown to be robust on most of the dynamic scene conditions, but because of its slowness  framed differencing was preferred. In saliency (Section \ref{sec:sal}), hierarchical color based, context aware, spectral distribution based and region contrast were studied and it was evident that region color (texture) contrast approach had rendered a high quality saliency maps.

\par Temporal smoothening enables to focus the visual attention score (the probability of an event occurring at given pixel) across frames that are obtained by fusing the variation measure of background subtraction and saliency map measure. It helped obtain a clear boundaries distinguishing source of the event. Spatio temporal volume (STV) is generated from the smoothened mask by a unique approach of tracking which further boosts resistance to sudden variation.

\par The indigenous convolutional neural network (CNN) was used for event classification of video segment from the  obtained STV. It was observed that these localized video segment (most probable event region) yielded a better model accuracy compared to the complete video segment. Also experiments revealed that raw color features as input to CNN-3D outperformed the processed features for the studied dataset. A hierarchical manner of classifying events was analysed as it enable train models concurrently and rapidly. A deep examination disclose its excellence over the single large classifier. 

\par This framework enlighten a new approach for solving problems in different applications like surveillance, automated annotation and more.

\section{Criticism}
\begin{itemize}
	\item{Focused only on spatial localization and failed to consider the temporal localization which is very important in any real time video. With the temporal localization the process of smoothening could have been eliminated}
	\item{Instead of event tracking by feature matching on every frame, a combination of current approach and standard tracking algorithm like Kanade–Lucas–Tomasi feature tracker (KLT) can be tried. Once a tracking window is obtained, the KLT algorithm can be use to track it, and current approach can regulate entry and exit of objects.}
	\item{Along with color and texture based saliency, optical flow based saliency might have helped obtain the confined mask corresponding to an event}
\end{itemize}
\clearpage 
\section{Future Work}
Would revisit the indigenous convolutional neural network (CNN), to incorporate hierarchical learning. Where the first layer of CNN is trained and then classes that are quite similar are clustered based on CNN bottleneck features. Subsequent layers are trained in a way to discriminate the classes which were considered similar in previous layer. This help raise the performance of the classification on a large dataset as the task is being delegated efficiently to multiple simple classifiers.
\par Also want to explore ways for associating the objects and events that are present in the given video segment to build a knowledge base by annotating them in the video. It helps for sophisticated video content retrieval by allowing to step to the queried region within a video.