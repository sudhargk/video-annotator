\chapter{EXPERIMENTAL RESULTS}
\label{chap:exp}
The proposed event recognition technique incorporate background subtraction, saliency estimation and temporal smoothening.  This chapter justifies the reason for choosing appropriate technique for each block in the proposed algorithm.  The evaluation of background subtraction was done intuitively.  Among the multiple techniques for background subtraction the frame-differencing was chosen because it was swift and yielded results comparable to that of eigen subtraction and mixture of gaussian.
\par In section \ref{sec:EvS} the performance of saliency estimation is been examined on  weizmann segmentation dataset.  As discussed localization is focussed on extracting bounding box corresponding to an event which is achieved by smoothening the  visual attention score that was obtained from background subtraction and saliency estimation.  In section \ref{sec:EvLoc}, we examine the localization on the change detection dataset.  
Finally the complete algorithm proposed is evaluated on the UCF-50 dataset by using the indigenous deep neural network toolkit.  The configuration and results of which are explained in \ref{sec:EvVS}

\section{Evaluation of Saliency}
\label{sec:EvS}
Different techniques for estimation of saliency has been already discussed in section \ref{sec:sal}.  Weizmann segmentation dataset was considered for the evaluation.  It has around 200 image which includes images that clearly depict one or two object/s with ground truth segmentations. The database contains images, whose surroundings differs the foreground  either in intensity, texture, or other low level cues to avoid dubiousness.  The precision, recall and f-measure for different saliency estimation techniques on one and two object/s are shown in Table \ref{tab:salOneObj} and Table \ref{tab:salTwoObj} respectively. 
\par It was observed from the table that the HCB and CAB did not yield many positives, while SDB generated too many positives but not many true positives. Technique RC+D and RC which are region contrast with and without distribution measure was shown to work well for one object and multiple object respectively.
\begin{table}[htbp]
   \caption{Results for the single object segmentation}
   \begin{center}
   \begin{tabular}{|l|c|c|c|} \hline
     \textbf{methods} & \textbf{precision} & \textbf{recall} & \textbf{f-measure} \\ \hline
     \emph{HCB} & 0.425 & 0.312 & 0.294 \\
	 \emph{CAB} & 0.418 & 0.363 & 0.355 \\
 	 \emph{SDB} & 0.469 & 0.735 & 0.514 \\
	 \emph{RC}  & 0.772 & 0.769 & 0.730 \\
	 \emph{RC~+~D} & 0.703	& 0.862 & 0.733	\\ \hline
   \end{tabular}
   \label{tab:salOneObj}
   \medskip \small 
   \end{center}
 \end{table}
\begin{table}[htbp]
   \caption{Results for the multiple object segmentation}
   \begin{center}
   \begin{tabular}{|l|c|c|c|} \hline
     \textbf{methods} & \textbf{precision} & \textbf{recall} & \textbf{f-measure} \\ \hline
     \emph{HCB} & 0.396 & 0.434 & 0.339 \\
	 \emph{CAB} & 0.573 & 0.475 & 0.473 \\
 	 \emph{SDB} & 0.360 & 0.674 & 0.392 \\
	 \emph{RC}  & 0.763 & 0.772 & 0.732 \\ \hline
   \end{tabular}
   \label{tab:salTwoObj}
   \end{center}
 \end{table} 
\par Since RC single handedly outperform other techniques it was considered for measuring the saliency of individual frames.  As we expect multiple salient object to exist, RC+D was not preferred for the saliency estimation.
 
\section{Evaluation of Localization}
\label{sec:EvLoc}
The change detection dataset \citep{cdnet} provides  a realistic, camera-captured (no CGI), diverse set of videos with challenges like dynamic background, camera jitter, intermittent object motion, shadows and more.  The dataset considers the change/variation in frames to correspond to an event. Hence the change detection is being mapped to the event localization.  The figure \ref{fig:changeDb} illustrates the localization of change detection dataset videos.
\begin{figure}[htpb]
   \begin{center}
	    \includegraphics[width=0.8\textwidth]{snaps/smooth/changeDS.eps}     
     \caption {Illustration of localization on change detection dataset}
   \label{fig:changeDb}
    \medskip \small The odd and even rows depict the ground truth and predicted mask respectively for change detection dataset videos. 
   \end{center}
 \end{figure}
\begin{table}[htbp]
   \caption{Results of event localization on change detection dataset}
   \begin{center}
   \begin{tabular}{|l|c|c|c|} \hline
        \textbf{challenges} & \textbf{precision} & \textbf{recall} & \textbf{f-measure} \\ \hline
		bad Weather & 0.16 & 0.78 & 0.26\\
		baseline & 0.19 & 0.83 & 0.28\\
		camera Jitter & 0.13 & 0.70 & 0.21 \\
		dynamic Background & 0.11 & 0.55 &  0.18\\
		intermittent Object Motion & 0.11 & 0.62 & 0.18 \\
		low Frame rate & 0.14 & 0.44 & 0.20 \\
		night Videos & 0.50 & 0.70 & 0.14 \\
		PTZ & 0.05 & 0.74 & 0.09\\
		shadow & 0.13 & 0.64 & 0.20\\ \hline
   \end{tabular}
   \label{tab:evalLoc}
   \end{center}
 \end{table} 
\par The results of localization of video event for different scenarios on change detection dataset are shown in Table \ref{tab:evalLoc}. For almost all scenarios the precision for the region mask is observed to be not so high, this is because the approach expects foreground to be present on every frame which was not true for the dataset which in turn generated many false positives as it can be observed in Figure \ref{fig:changeDb}.  The dataset also included information on the region of interest which was not considered by the algorithm.  But it is evident from the results that the GMM based temporal smoothening is able to capture the interesting regions within a video and help obtain the spatio temporal volume for event prediction.

\section{Evaluation of Video Classification} 
\label{sec:EvVS}
Video classification is performed using 3D CNNs.  The experimental results for the recognition is obtained for UCF-50 dataset which is an action recognition dataset with 50 action categories,	 containing realistic videos taken from youtube.  This data set is very difficult because of the diverse object appearance (pose), object scale, viewpoint, cluttered background, illumination conditions, etc.  
\par In the dataset video classes are clubbed to form groups like body-motion (BM), human-object interaction (HOI), playing musical instruments (PI), indoor sports (IS) and outdoor sports (OS).   Advantage of this information was taken by building multiple classifier for each groups, this not only helped in improving the prediction but also enabled building models concurrently. The following approaches were examined on $\approx{5}$ hours of training data of the UCF-50 dataset,
\begin{enumerate}
	\item{\textbf{Approach I:} In this approach five frame context was considered, and in a frame active pixel obtained from localization are replaced by gray value while the inactive pixels are replaced by zeros.  Frames are then resized to 120x90 dimension for faster processing.  The CNN consists of three convolutional and sub-sampling layer,  followed by a single MLP layer of size 250.}
	\item{\textbf{Approach II:} A five frame context was considered, instead of entire frame only the window obtained from tracking is provided.  Windows are smartly resized to 80x60, so that resolution of the window are not altered.  All three channels are given to CNN which constitute of three convolutional and sub-sampling layer,  followed by a single MLP layer of size 250.}
	\item{\textbf{Approach III:} It is very similar to the Approach II, where instead of all color channel, gray channel and the frame differencing of consecutive frames are provided as input filters.}	
\end{enumerate}
\begin{table}[htbp]
   \caption{Test error (in \%) of combined UCF-50 dataset}
   \begin{center}
   \begin{tabular}{|l|c|} \hline
        \textbf{Approach}&  \textbf{Combined} \\ \hline
        I & 40.14\\ \hline
		II (with norm) &  17.07 \\ \hline		 
		III (with norm) &  25.23 \\ \hline
		\cite{recognizing50} &  33.26 \\ \hline
   \end{tabular}
   \label{tab:comrecognition}
   \medskip \small 
   \end{center}
 \end{table} 
 
\begin{table}[htbp]
   \caption{Test error (in \%) of UCF-50 dataset for individual groups}
   \begin{center}
   \begin{tabular}{|l|c|c|c|c|c|} \hline
        \textbf{Approach} & \textbf{BM} & \textbf{HOI} & \textbf{PI} & \textbf{IS} & \textbf{OS} \\ \hline
		II & 8.63 & 3.85 & 1.36 & 2.21 & 9.21 \\ \hline
		II (with norm) & 8.51 & 3.69 & 1.33 & 2.19 & 9.08 \\ \hline		 
		III (with norm) & 27.45 & 14.39 & 5.48 & 6.27 & 33.24 \\ \hline
   \end{tabular}
   \label{tab:indirecognition}
   \medskip \small 
   \end{center}
 \end{table} 
  
Among the three approaches, it can be clearly observed from the Table \ref{tab:comrecognition} that the approach II and III  stand out.  Since the number of examples in different class of videos were skewed, the normalization was performed (random examples are left out) to have nearly same number of examples in each class.  It is evident from the results of Table \ref{tab:indirecognition} that performance improved after normalization. When compared with \citep{recognizing50}, the results obtained are extraordinary since results are gathered for every five frame context rather than the complete video.
\par All the above experiments are tested using the indigenous python-DNN toolkit on  Xeon(R) CPU E5-2650 v2 @ 2.60GHz in CPU mode and Intel(R) Xeon(R) CPU E3-1240 v3 @ 3.40GHz in the GPU mode. With the support of very high primary memory in  the first system, entire dataset was loaded allowing reduced secondary memory access.

\section{Summary}
The experiments shows that RC combined with simple FD,  followed by GMM based temporal smoothening gives a satisfying results in isolating multiple event regions.  It was also evident that the  hierarchical classification yielded  faster convergence enabling parallel training.  The results obtained by the novel approach  for UCF dataset is far better than the existing state of the art results.  In the next chapter the summary, criticism and future scope of the work will be discussed.