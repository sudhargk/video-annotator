\chapter{EXPERIMENTAL RESULTS}
\label{chap:exp}
This chapter justifies the reason for choosing appropriate set of techniques for event recognition based on  experiments conducted. The first stage of the task involve localization, which incorporate background subtraction, saliency estimation and temporal smoothening as discussed in Chapter \ref{chap:eventLo}. Evaluation of background subtraction was done intuitively, among the techniques frame-differencing was chosen over eigen subtraction for its pace. In case of saliency estimation tests were performed on weizmann segmentation dataset which is discussed in \ref{sec:EvS}. End to end assessment of the localization algorithm was done on the change detection dataset, while recognition was examined on the UCF-50 dataset.

\section{Evaluation of Saliency}
\label{sec:EvS}
In section \ref{sec:sal}, different techniques for estimation of saliency had been discussed, comparison of the result for these techniques can be seen in Table \ref{tab:salOneObj} and Table \ref{tab:salTwoObj}. Evaluation are done on weizmann segmentation dataset which has 200 image with ground truth segmentations.The database only includes images that clearly depict one or two object/s in the foreground that differ from its surroundings by either intensity, texture, or other low level cues to avoid dubiousness. HCB, CAB do not yield many positives, while SDB generates many positives, most of which are not true positives. RC+D and RC are region contrast with and without distribution measure. RC+D works well for one object while for multiple object RC performs better.
\begin{table}[htbp]
   \caption{Results for the single object segmentation}
   \begin{center}
   \begin{tabular}{|l|c|c|c|} \hline
     methods & precision & recall & f-measure \\ \hline
     HCB & 0.425 & 0.312 & 0.294 \\
	 CAB & 0.418 & 0.363 & 0.355 \\
 	 SDB & 0.469 & 0.735 & 0.514 \\
	 RC  & 0.772 & 0.769 & 0.730 \\
	 RC~+~D & 0.703	& 0.862 & 0.733	\\ \hline
   \end{tabular}
   \label{tab:salOneObj}
   \medskip \small 
   \end{center}
 \end{table}
\begin{table}[htbp]
   \caption{Results for the multiple object segmentation}
   \begin{center}
   \begin{tabular}{|l|c|c|c|} \hline
     \textbf{challenges} & \textbf{precision} & \textbf{recall} & \textbf{f-measure} \\ \hline
     HCB & 0.396 & 0.434 & 0.339 \\
	 CAB & 0.573 & 0.475 & 0.473 \\
 	 SDB & 0.360 & 0.674 & 0.392 \\
	 RC  & 0.763 & 0.772 & 0.732 \\ \hline
   \end{tabular}
   \label{tab:salTwoObj}
   \end{center}
 \end{table} 
\par RC is being considered for measuring the saliency of individual frames as it outperforms all the techniques discussed. RC+D was not considered for the later experiment, as multiple salient object might exist.
 
\section{Evaluation of Localization}
Localization of the event for change detection dataset \citep{cdnet} is performed . The dataset provides  a realistic, camera-captured (no CGI), diverse set of videos with challenges  like dynamic background, camera jitter, intermittent object motion, shadows, thermal signatures and more. This results of localization for different video scenarios are shown in Table \ref{tab:evalLoc}.

\begin{table}[htbp]
   \caption{Results of event localization on change detection dataset}
   \begin{center}
   \begin{tabular}{|l|c|c|c|} \hline
        \textbf{challenges} & \textbf{precision} & \textbf{recall} & \textbf{f-measure} \\ \hline
		bad Weather & 0.16 & 0.78 & 0.26\\
		baseline & 0.19 & 0.83 & 0.28\\
		camera Jitter & 0.13 & 0.70 & 0.21 \\
		dynamic Background & 0.11 & 0.55 &  0.18\\
		intermittent Object Motion & 0.11 & 0.62 & 0.18 \\
		low Frame rate & 0.14 & 0.44 & 0.20 \\
		night Videos & 0.50 & 0.70 & 0.14 \\
		PTZ & 0.05 & 0.74 & 0.09\\
		shadow & 0.13 & 0.64 & 0.20\\ \hline
   \end{tabular}
   \label{tab:evalLoc}
   \end{center}
 \end{table} 
\par The precision for the region mask is not so high, because the approach of smoothening considers foreground to be present in every frame. Since this assumptions did not hold true for the dataset, we observed lot many false positives.  Also in the dataset, information over the region of interest were provided but was not considered by the algorithm. Still it is evident from the results that the GMM based smoothening is able to capture the interesting regions within a video and would help obtain the spatio temporal volume.

\section{Evaluation of Video Classification} 
Video classification are done using 3d CNN's, the experimental results for the event recognition is obtained for UCF-50 dataset. It is an action recognition dataset with 50 action categories, containing of realistic videos taken from youtube. This data set is very difficult because of the diverse object appearance and pose, object scale, viewpoint, cluttered background, illumination conditions, etc. The dataset includes $\approx{5}$ hours of training data. Some of the approaches that were experimented for this task are discussed below,
\begin{enumerate}
	\item{\textbf{Approach I:} In this approach complete five frame context was considered, and in a frame active pixel obtained from localization are replace by gray value while the inactive pixel are replace by zeros. Frames are then resized to 120x90 dimension for faster evaluation. CNN constitute of three convolutional and sub-sampling layer,  followed by a single MLP layer of 250.}
	\item{\textbf{Approach II:} Again a five frame context was considered, instead of entire frame only the window obtained from tracking is provided.  Windows are smartly resized to 80x60 , so that resolution of the window are not altered. All three channels are given to CNN .CNN constitute of three convolutional and sub-sampling layer,  followed by a single MLP layer of size 250.}
	\item{\textbf{Approach III:} It is very similar to the Approach 2, where instead of all color channel, gray channel and foreground mask are provided input filters.}	
\end{enumerate}
\begin{table}[htbp]
   \caption{Test error (in \%) for event recognition in UCF-50}
   \begin{center}
   \begin{tabular}{|l|c|c|c|c|c|c|} \hline
        \textbf{Approach} & \textbf{BM} & \textbf{HOI} & \textbf{PI} & \textbf{IS} & \textbf{OS} & Overall \\ \hline
        I & & & & & & 40.14\\ \hline
		II & 8.63 & 3.85 & 1.36 & 2.21 & 9.21 & \\ \hline
		II (after norm) & 8.51 & 3.69 & 1.33 & 2.19 & 9.08 & \\ \hline		 
		III (after norm) & 27.45 &  & 5.48 & & 33.24 & \\ \hline
   \end{tabular}
   \label{tab:recognition}
   \medskip \small 
   \end{center}
 \end{table} 
Among the three approach it can be clearly observed from the table \ref{tab:recognition} that the approach 2 and approach 3 to stand out compared to first approach. Also the number of examples in different class of videos were skewed, hence normalization was done (random examples are left out) to have nearly same number of examples in each class. It is evident from the results that performance improved after normalization.

\par In the dataset video classes are clubbed to form groups like Body-Motion (BM), Human-Object Interaction (BOI), Playing Musical Instruments (PI), Indoor Sports (IS) and Outdoor Sports (OS). Advantage of this information was taken by building multiple classifier for each groups, this not only helped in improving the prediction but also enabled to build models concurrently.

\par All the above experiments are tested using the indigenous CNN on  Xeon(R) CPU E5-2650 v2 @ 2.60GHz in CPU mode and Intel(R) Xeon(R) CPU E3-1240 v3 @ 3.40GHz in the GPU mode. With the support of very high primary memory in  the first system, entire dataset was loaded allowing reduced secondary memory access.

\section{Summary}
RC combined with simple FD are used for isolating different regions. which are further polished by the GMM based smoothening. Hierarchical classification enabled faster convergence and parallel training. The results obtained for UCF dataset is far better than the existing state of the art results.