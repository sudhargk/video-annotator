\chapter{INTRODUCTION}
\label{chap:intro}
In the era of Google glass \citep{googleGlass}, %people wants everything in front of them to be explicable.
everybody wants everything, including video to be explained in detail.  Just like in football, one would like to obtain the highlights of a match in terms of statistics, such as duration of ball control by respective team and more,  while in the sphere of surveillance, detecting multiple simultaneous events is very crucial.  All these tasks are broadly categorized as applications	 of video event recognition. 

\par A video event is defined as \textit{a fact or process of doing things to attain a goal}.  The video events may be of short duration like a player kicking the ball or of long duration like a player scoring a goal.  It is noticed that most of the annotated events available are short events. Even long events can be modelled as sequence of short events.  Only short events are considered in this work. The subject of an event can be any physical object like human, ball etc..
\par The task of video event recognition is generally framed as prediction of video events from a given set of labelled random videos (such as available from youtube), where the labels specify the events that occurs within the video.  But most of the available datasets are in weakly labelled settings, i.e, they do not have spatio-temporal segmentation indicating coordinates and time points corresponding to which event occurs and where.  Therefore the particular problem can be bifurcated into \textit{localization} and \textit{identification} problems.  The localization aspect of the problem is the task of locating the event within the video %and further build train of frame corresponding to the event
and then building a sequence of frames.  The sequence of frames that correspond to the spatio temporal volume (STV) and are used by models for the prediction.
\par Even though the identification appears to be simple, there are quite a lot of challenges.  Most of the challenges observed are centred around the source of the video like dynamic background, moving camera, low lighting and more.  Another challenging aspect of this problem is to deal with large intra-category variations for achieving satisfactory classification on wide range of videos.
\par Generally, such problems are tackled in the following manner : local feature extraction, feature aggregation, and finally a classifier (such as SVM) to distinguish among the visual classes of interest.  But this approach suffers from a major challenge, namely, the choice of feature that best represents the video.  In the last few years, deep neural networks have revolutionized the machine learning field and have edified a new approach to training.  In the case of a deep neural network, it accepts raw input rather than the processed features and generates (bottleneck) features in the process of prediction. 
\par Convolutional neural network (CNN), a deep learning method, has shown to be remarkably succesful for the visual recognition task as it takes advantage of the spatial structure of images/videos.  It was also observed to be resistant to translational variations and support several regularization tricks for addressing the large intra-category variances.  Therefore, CNN's are considered for  the event recognition problem.
\clearpage

\section{Outline of the Work}
A novel solution to the problem of video localization and identification has been proposed. In the approach, background subtraction is performed on the input video to measure variation in pixel the intensity in continuous frames.  The saliency measure is obtained for a sequence (train) of frames that capture the regions in the frame that are quite distinct in that frame.  Both the measures are fused to obtain a new score termed visual attention score (VAS) that can capture the motion as well as the contrast in a given frame. 
\par CNN has been considered for event recognition and expects fixed size raw image/video as input. A spatio temporal volume (STV) corresponding to the video event is extracted by smoothening the VAS to obtain a bounding box that is being tracked along the sequence of frames.  Figure \ref{fig:outline}  depicts the outline of the proposed solution to the event recognition problem.
\begin{figure}[htpb]
   \begin{center}
	   	{%
			\setlength{\fboxsep}{5pt}%
			%\setlength{\fboxrule}{1pt}%
	    		\fbox{\includegraphics[width=0.95\textwidth]{snaps/outline.eps}}  
	    }%
     \caption {Proposed solution for video event recognition}
   \label{fig:outline}
   \end{center}
 \end{figure}
\section{Major Contribution}
\begin{itemize}
	\item{Built a indigenous deep neural network toolkit, including an easy way to configure
it for different neural network models.}
	\item{Proposed a novel approach for video event localization by fusing the background subtraction and saliency measures.}
	\item{Suggested different ways for performing temporal smoothening over the visual attention score by considering a temporal context.}
	\item{Devised an algorithm for extracting the spatio temporal volume from the smoothed scores.}
\end{itemize}

\section{Organization of thesis}
\par Chapter \ref{chap:eventLo} contains the steps for extracting the spatio-temporal volume by fusing background subtraction and saliency measures.  While Chapter \ref{chap:eventrec} includes a discussion on the existing techniques used for event identification and our home-grown implementation of neural network for the same.  The experiments for the event recognition and the justification for choosing the appropriate techniques for the ultimate model are chalked in Chapter \ref{chap:exp}.  The future scope and the summary of the entire work can be seen in Chapter \ref{chap:concl}.